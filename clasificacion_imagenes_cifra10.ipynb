{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>train</th>\n",
       "      <th>label_id</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image25107.jpg</td>\n",
       "      <td>apparel</td>\n",
       "      <td>images/apparel/image25107.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image26799.jpg</td>\n",
       "      <td>apparel</td>\n",
       "      <td>images/apparel/image26799.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image23088.jpg</td>\n",
       "      <td>apparel</td>\n",
       "      <td>images/apparel/image23088.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image0421.jpg</td>\n",
       "      <td>apparel</td>\n",
       "      <td>images/apparel/image0421.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image15994.jpg</td>\n",
       "      <td>apparel</td>\n",
       "      <td>images/apparel/image15994.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name    label                           path  train  label_id  \\\n",
       "0  image25107.jpg  apparel  images/apparel/image25107.jpg   True         9   \n",
       "1  image26799.jpg  apparel  images/apparel/image26799.jpg   True         9   \n",
       "2  image23088.jpg  apparel  images/apparel/image23088.jpg   True         9   \n",
       "3   image0421.jpg  apparel   images/apparel/image0421.jpg   True         9   \n",
       "4  image15994.jpg  apparel  images/apparel/image15994.jpg   True         9   \n",
       "\n",
       "   image_id  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  \n",
       "3         3  \n",
       "4         4  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "%reload_ext autoreload\n",
    "from utils import load_images\n",
    "from features import extract_features, load_features, save_features\n",
    "\n",
    "images_paths, images = load_images(True)\n",
    "images_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023841381072998047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 550,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bb4833860c4d0ebeab2b7f88c01bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de  descriptores: 32\n",
      "Número de  descriptores: 17102\n",
      "Número Máximo de Descriptores Por Imágen : 35\n",
      "Número Medio  de Descriptores Por Imágen : 31\n",
      "Número Mínimo de Descriptores Por Imágen : 3\n"
     ]
    }
   ],
   "source": [
    "def orb_descriptor(image):\n",
    "    orb = cv2.ORB_create(nfeatures = 50, scoreType = cv2.ORB_HARRIS_SCORE, WTA_K = 4)\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    _, descs = orb.detectAndCompute(img, None)\n",
    "    return descs\n",
    "\n",
    "# Convertir las imágenes a escala de grises y aplicar SIFT en el subconjunto de imágenes\n",
    "descriptors, index = extract_features(orb_descriptor, images, min_features=3, progress = True)\n",
    "print(\"Tamaño de  descriptores:\", descriptors.shape[1])\n",
    "print(\"Número de  descriptores:\", descriptors.shape[0])\n",
    "print(\"Número Máximo de Descriptores Por Imágen :\", pd.value_counts(index).max())\n",
    "print(\"Número Medio  de Descriptores Por Imágen :\", pd.value_counts(index).mean().round(0).astype(int))\n",
    "print(\"Número Mínimo de Descriptores Por Imágen :\", pd.value_counts(index).min())\n",
    "\n",
    "save_features(descriptors, index, images_paths, \"ORB\")\n",
    "#descriptors = np.concatenate(descriptors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(263, 5),\n",
       " (762, 4),\n",
       " (381, 4),\n",
       " (207, 3),\n",
       " (166, 3),\n",
       " (81, 3),\n",
       " (956, 3),\n",
       " (508, 3),\n",
       " (779, 3),\n",
       " (453, 2)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Crear un modelo de k-NN\n",
    "knn_model = NearestNeighbors(n_neighbors=30)  # Buscar los 5 vecinos más cercanos\n",
    "knn_model.fit(lista_desciptores_aplanado)  # Ajustar el modelo a los descriptores\n",
    "\n",
    "# Función para encontrar los vecinos más cercanos para un descriptor dado\n",
    "def find_nearest_neighbors(descriptor, k = 10):\n",
    "    descriptor_flat = descriptor.flatten()\n",
    "    # Encontrar los índices y distancias de los vecinos más cercanos\n",
    "    distances, indices = knn_model.kneighbors([descriptor_flat], k)  # Obtener k vecinos más cercanos\n",
    "    return distances, indices\n",
    "\n",
    "# Ejemplo: Encontrar vecinos más cercanos para el primer descriptor en la primera imagen\n",
    "contador = Counter()\n",
    "lista = []\n",
    "print(len(descriptor_busqueda[0]))\n",
    "for descriptor in descriptor_busqueda[0]:\n",
    "    distances, indices = find_nearest_neighbors(descriptor, 20)\n",
    "    lista.extend([index[indice] for indice in indices[0]])\n",
    "\n",
    "print(len(lista))\n",
    "Counter(lista).most_common(10)\n",
    "# Imprimir los índices de los vecinos más cercanos y sus distancias\n",
    "#print(\"Índices de los vecinos más cercanos:\", indices)\n",
    "#print(\"Distancias a los vecinos más cercanos:\", distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('uint8'), dtype('uint8'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orb_descriptor(images[1]).dtype, descriptors.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18, 137,  46, 192, 177,  65, 185,  13, 192, 124,  28,  77,  19,\n",
       "         37, 197, 164,  94, 139, 169,  98, 111, 228,  70, 159, 135, 158,\n",
       "        245, 168,  96, 130, 249, 100],\n",
       "       [ 62, 134,  62,  12,  57,  81, 106,   9, 128,  44,  30, 141, 177,\n",
       "        249,  23, 180, 196, 182, 169,  45, 108, 108, 119,  28, 155, 155,\n",
       "        195, 132,  97, 227,  73, 173],\n",
       "       [ 96, 106, 144, 219, 152,  75, 237, 126,  33, 126, 115,  53, 238,\n",
       "         82,  29, 140, 231,   2,  93, 128, 202,  37,  22, 168, 234, 195,\n",
       "        181, 207, 149, 144, 151, 206],\n",
       "       [ 96,  74,  88, 200, 144,  75,  61, 125,  34, 126,  95, 141, 239,\n",
       "         18,  25, 132,  87,  17,  41,  35, 206,  36,  22, 153, 216, 194,\n",
       "        149, 207, 100, 144, 151,  66],\n",
       "       [106,  77,  95, 138, 128,  83, 170, 125,  18, 237, 158,  77, 224,\n",
       "         34, 222, 135, 207,  59, 107, 110,  51,  36,  40,  40, 226, 170,\n",
       "         49, 207, 144,  22, 102, 144],\n",
       "       [ 34, 139,  94, 200, 128, 115, 185,  29,   0,  62,  28,  77, 211,\n",
       "         33,  25, 132, 214, 131, 169,  97, 254,  36, 118,  28, 155, 150,\n",
       "        105, 108,  64, 163, 150,  68],\n",
       "       [174, 132,  90, 139, 148, 216,  62, 141,  33,  62, 220, 143, 206,\n",
       "        185,  29,   4, 215,  98,  41,  32, 206,  36, 112,  24, 164, 178,\n",
       "         77, 107, 165, 173, 219, 190],\n",
       "       [170, 121,  90, 192, 128, 224, 190,  92,   2, 254, 156, 143, 239,\n",
       "         32, 222, 139, 215,  75,  99,  50, 242,  37, 120,  42,  92,  44,\n",
       "        181, 107,  80,   6, 150,  96],\n",
       "       [108,  26, 208,  27, 140, 219, 205, 126, 225, 142,  19, 131, 222,\n",
       "         64,  25, 141, 214, 192, 146,  16, 202,  37,  22, 170, 216,  64,\n",
       "        177, 207, 132, 168, 147, 198],\n",
       "       [160, 110,  88, 208, 154, 248,  45, 158,  34, 158,  70, 191, 107,\n",
       "         29,   9, 189,  17,  18, 210,   1, 206,  69, 214, 187,  88,  70,\n",
       "        166, 123, 103, 224, 151,  74]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptors[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'cv2.DMatch' object has no attribute '__dict__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ruben\\Documents\\Universidad\\4\\AAPI\\CBIR\\clasificacion_imagenes_cifra10.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ruben/Documents/Universidad/4/AAPI/CBIR/clasificacion_imagenes_cifra10.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m feat \u001b[39m=\u001b[39m descriptors[\u001b[39m0\u001b[39m, :]\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ruben/Documents/Universidad/4/AAPI/CBIR/clasificacion_imagenes_cifra10.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mat \u001b[39m=\u001b[39m matcher\u001b[39m.\u001b[39mknnMatch(feat, descriptors, \u001b[39m50\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ruben/Documents/Universidad/4/AAPI/CBIR/clasificacion_imagenes_cifra10.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mat[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'cv2.DMatch' object has no attribute '__dict__'"
     ]
    }
   ],
   "source": [
    "matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "feat = descriptors[0, :].reshape(1, -1)\n",
    "mat = matcher.knnMatch(feat, descriptors, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.DMatch 000001DDB4624530>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
